{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1034b127",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069e0a4d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Импорт-модулей-и-константы\" data-toc-modified-id=\"Импорт-модулей-и-константы-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Импорт модулей и константы</a></span></li><li><span><a href=\"#Настройка-логирования\" data-toc-modified-id=\"Настройка-логирования-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Настройка логирования</a></span></li><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Базовая-модель\" data-toc-modified-id=\"Базовая-модель-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Базовая модель</a></span></li><li><span><a href=\"#Новые-признаки\" data-toc-modified-id=\"Новые-признаки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Новые признаки</a></span></li><li><span><a href=\"#Добавление-кластеризации\" data-toc-modified-id=\"Добавление-кластеризации-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Добавление кластеризации</a></span></li><li><span><a href=\"#Логистическая-регрессия-как-признак\" data-toc-modified-id=\"Логистическая-регрессия-как-признак-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Логистическая регрессия как признак</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00432e09",
   "metadata": {},
   "source": [
    "## Импорт модулей и константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c90113e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "from category_encoders.m_estimate import MEstimateEncoder\n",
    "from joblib import load\n",
    "import numpy as np\n",
    "import optuna\n",
    "# from optuna.integration import CatBoostPruningCallback\n",
    "import pandas as pd\n",
    "import shap\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "from useful_funcs import make_notifier\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "N_JOBS = -1\n",
    "CV=5\n",
    "N_TRIALS = 1000\n",
    "\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d187e2d",
   "metadata": {},
   "source": [
    "## Настройка логирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "685844c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_notification = make_notifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056fe31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_notification(\n",
    "    \"Titanic - Machine Learning from Disaster. CatBoost\"\n",
    "    \"\\n\\nМодули импортированы.\"\n",
    "    \"\\nЛогирование настроено.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12afb1a",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "Загрузим тренировочный и тестовый наборы данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90a2b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load(\"train_set.joblib\")\n",
    "X_test, y_test = load(\"test_set.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d97dfc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 712 entries, 692 to 507\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  712 non-null    int64  \n",
      " 1   Pclass       712 non-null    int64  \n",
      " 2   Name         712 non-null    object \n",
      " 3   Sex          712 non-null    object \n",
      " 4   Age          575 non-null    float64\n",
      " 5   SibSp        712 non-null    int64  \n",
      " 6   Parch        712 non-null    int64  \n",
      " 7   Ticket       712 non-null    object \n",
      " 8   Fare         712 non-null    float64\n",
      " 9   Cabin        160 non-null    object \n",
      " 10  Embarked     710 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 66.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>693</td>\n",
       "      <td>3</td>\n",
       "      <td>Lam, Mr. Ali</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>482</td>\n",
       "      <td>2</td>\n",
       "      <td>Frost, Mr. Anthony Wood \"Archie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239854</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>528</td>\n",
       "      <td>1</td>\n",
       "      <td>Farthing, Mr. John</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17483</td>\n",
       "      <td>221.7792</td>\n",
       "      <td>C95</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>856</td>\n",
       "      <td>3</td>\n",
       "      <td>Aks, Mrs. Sam (Leah Rosen)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>392091</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>802</td>\n",
       "      <td>2</td>\n",
       "      <td>Collyer, Mrs. Harvey (Charlotte Annie Tate)</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 31921</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                         Name     Sex   \n",
       "692          693       3                                 Lam, Mr. Ali    male  \\\n",
       "481          482       2             Frost, Mr. Anthony Wood \"Archie\"    male   \n",
       "527          528       1                           Farthing, Mr. John    male   \n",
       "855          856       3                   Aks, Mrs. Sam (Leah Rosen)  female   \n",
       "801          802       2  Collyer, Mrs. Harvey (Charlotte Annie Tate)  female   \n",
       "\n",
       "      Age  SibSp  Parch      Ticket      Fare Cabin Embarked  \n",
       "692   NaN      0      0        1601   56.4958   NaN        S  \n",
       "481   NaN      0      0      239854    0.0000   NaN        S  \n",
       "527   NaN      0      0    PC 17483  221.7792   C95        S  \n",
       "855  18.0      0      1      392091    9.3500   NaN        S  \n",
       "801  31.0      1      1  C.A. 31921   26.2500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.info()\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ca2b4",
   "metadata": {},
   "source": [
    "## Базовая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2b5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(\n",
    "    data=X_train.fillna(-999),\n",
    "    label=y_train, \n",
    "    cat_features=['PassengerId', 'Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked'],\n",
    "    text_features=['Name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44639344",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    loss_function = metrics.Logloss(),\n",
    "    custom_loss=[metrics.Accuracy(), metrics.AUC()],\n",
    "    random_seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a34621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=CV, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1585181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164f5cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59bb91040da4a5cba031ea8f829fe1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_data = cv(\n",
    "    pool=train_pool, \n",
    "    params=model_params, \n",
    "    logging_level='Silent', \n",
    "    plot=True,\n",
    "    folds=skf.split(X_train.fillna(-999), y_train),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c60a4d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean accuracy: 0.836\n",
      "Accuracy std: 0.0226\n"
     ]
    }
   ],
   "source": [
    "best_id = np.argmax(cv_data['test-Accuracy-mean'])\n",
    "\n",
    "print(f\"Best mean accuracy: {np.round(cv_data['test-Accuracy-mean'][best_id], 3)}\")\n",
    "print(f\"Accuracy std: {np.round(cv_data['test-Accuracy-std'][best_id], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370ba69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.81818182 0.78321678 0.85915493 0.85211268 0.80985915]\n",
      "mean accuracy: 0.8245050723923963\n",
      "accuracy std: 0.028007147831220762\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    loss_function = metrics.Logloss(),\n",
    "    cat_features=['PassengerId', 'Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked'],\n",
    "    text_features=['Name'],\n",
    "    random_seed=SEED,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    estimator=model,\n",
    "    X=X_train.fillna(-999),\n",
    "    y=y_train,\n",
    "    scoring='accuracy',\n",
    "    cv=CV,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "print(f'Scores: {scores}')\n",
    "print(f'mean accuracy: {scores.mean()}')\n",
    "print(f'accuracy std: {scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ba801ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>693</td>\n",
       "      <td>3</td>\n",
       "      <td>Lam, Mr. Ali</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>482</td>\n",
       "      <td>2</td>\n",
       "      <td>Frost, Mr. Anthony Wood \"Archie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239854</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>528</td>\n",
       "      <td>1</td>\n",
       "      <td>Farthing, Mr. John</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17483</td>\n",
       "      <td>221.7792</td>\n",
       "      <td>C95</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>856</td>\n",
       "      <td>3</td>\n",
       "      <td>Aks, Mrs. Sam (Leah Rosen)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>392091</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>802</td>\n",
       "      <td>2</td>\n",
       "      <td>Collyer, Mrs. Harvey (Charlotte Annie Tate)</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 31921</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                         Name     Sex   \n",
       "692          693       3                                 Lam, Mr. Ali    male  \\\n",
       "481          482       2             Frost, Mr. Anthony Wood \"Archie\"    male   \n",
       "527          528       1                           Farthing, Mr. John    male   \n",
       "855          856       3                   Aks, Mrs. Sam (Leah Rosen)  female   \n",
       "801          802       2  Collyer, Mrs. Harvey (Charlotte Annie Tate)  female   \n",
       "\n",
       "      Age  SibSp  Parch      Ticket      Fare Cabin Embarked  \n",
       "692   NaN      0      0        1601   56.4958   NaN        S  \n",
       "481   NaN      0      0      239854    0.0000   NaN        S  \n",
       "527   NaN      0      0    PC 17483  221.7792   C95        S  \n",
       "855  18.0      0      1      392091    9.3500   NaN        S  \n",
       "801  31.0      1      1  C.A. 31921   26.2500   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06db51d",
   "metadata": {},
   "source": [
    "## Новые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13adc682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_title(X, y=None, group_rare=False):\n",
    "    title = X.Name.str.extract(pat=r\"\\b,\\s(.+?)\\.\\s[\\b(]?\")\n",
    "    title = pd.Series(title[0], name=\"Title\").str.lower()\n",
    "\n",
    "    if group_rare:\n",
    "        title = title.where(\n",
    "            title.isin([\"mr\", \"miss\", \"mrs\", \"master\"]), \"aristocratic\"\n",
    "        )\n",
    "\n",
    "    return pd.concat([X, title], axis=\"columns\")\n",
    "\n",
    "\n",
    "def add_family(X, y=None):\n",
    "    family = X.Parch + X.SibSp\n",
    "    family.name = \"Family\"\n",
    "\n",
    "    return pd.concat([X, family], axis=\"columns\")\n",
    "\n",
    "\n",
    "def combine_fare_age(X, y=None):\n",
    "    data = X.copy()\n",
    "    data.loc[:, \"FareAgeComb\"] = data.Fare / data.Age\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def combine_fare_pclass(X, y=None):\n",
    "    data = X.copy()\n",
    "    data.loc[:, \"FarePclassComb\"] = data.Fare / data.Pclass\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def combine_sibsp_family(X, y=None):\n",
    "    data = X.copy()\n",
    "    data.loc[:, \"SibSpFamilyComb\"] = data.SibSp / (data.Family + 1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def combine_parch_family(X, y=None):\n",
    "    data = X.copy()\n",
    "    data.loc[:, \"ParchFamilyComb\"] = data.Parch / (data.Family + 1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_interaction(X, y=None):\n",
    "    res = X.copy()\n",
    "    col_list = X.select_dtypes(exclude='object').columns\n",
    "    \n",
    "    for i in range(len(col_list)):\n",
    "        for j in range(i + 1, len(col_list)):\n",
    "            res[f'{col_list[i]}_{col_list[j]}'] = res[col_list[i]] * res[col_list[j]]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc350a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(X, y=None, fill_vall=-999):\n",
    "    return (\n",
    "    X\n",
    "    .drop(columns='PassengerId')\n",
    "    .fillna(fill_vall)\n",
    "    .pipe(add_title, group_rare=True)\n",
    "    .pipe(add_family)\n",
    "    .pipe(combine_fare_age)\n",
    "    .pipe(combine_fare_pclass)\n",
    "    .pipe(combine_sibsp_family)\n",
    "    .pipe(combine_parch_family)\n",
    "    .pipe(get_interaction)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76acead",
   "metadata": {},
   "source": [
    "## Добавление кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8ddfd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, classifier_params=dict(n_estimators=100, max_depth=10), dbscans_params=dict()):\n",
    "        self.dbscans_params = dbscans_params\n",
    "        self.classifier_params =classifier_params\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        clusters_y = DBSCAN(**self.dbscans_params, n_jobs=N_JOBS).fit_predict(X)\n",
    "        \n",
    "        self.model = RandomForestClassifier(**self.classifier_params, n_jobs=N_JOBS).fit(X, clusters_y)\n",
    "        \n",
    "        return self\n",
    "  \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        res = X.copy()\n",
    "        res['cluster'] = self.model.predict(X)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4ea3439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7501d33c73c04f57af44b6874e0da62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_cols = ['Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Title']\n",
    "\n",
    "data_preps = Pipeline([\n",
    "    ('initial', FunctionTransformer(prep_data, kw_args=dict(fill_vall=-999))),\n",
    "    ('col_spliter', \n",
    "     ColumnTransformer(\n",
    "         [('pass', 'passthrough', ['Name'] + cat_cols),\n",
    "          ('preps', \n",
    "           Pipeline([\n",
    "               ('encoder',MEstimateEncoder(cols=cat_cols)),\n",
    "               ('scaler', StandardScaler()),\n",
    "               ('cluster', ClusterAdder()),\n",
    "               ('drop', FunctionTransformer(lambda x: x.drop(columns=cat_cols)))\n",
    "           ]),\n",
    "           [col for col in prep_data(X_train).columns if col != 'Name']\n",
    "          )\n",
    "         ], \n",
    "         remainder='passthrough',\n",
    "         verbose_feature_names_out=False\n",
    "     )\n",
    "    ),\n",
    "])\n",
    "\n",
    "prepared_data = data_preps.fit_transform(X_train, y_train)\n",
    "\n",
    "train_pool = Pool(\n",
    "    data=prepared_data, \n",
    "    label=y_train, \n",
    "    cat_features=cat_cols + ['cluster'],\n",
    "    text_features=['Name']\n",
    ")\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    loss_function = metrics.Logloss(),\n",
    "    custom_loss=[metrics.Accuracy(), metrics.AUC()],\n",
    "    random_seed=SEED,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# cv_data = cv(\n",
    "#     pool=train_pool, \n",
    "#     params=model.get_params(), \n",
    "#     logging_level='Silent', \n",
    "#     stratified=True, \n",
    "#     plot=True,\n",
    "#     fold_count=CV,\n",
    "# )\n",
    "\n",
    "cv_data = cv(\n",
    "    pool=train_pool, \n",
    "    params=model_params, \n",
    "    logging_level='Silent', \n",
    "#     stratified=True, \n",
    "    plot=True,\n",
    "    folds=skf.split(prepared_data, y_train),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09db97a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean accuracy: 0.888\n",
      "Accuracy std: 0.0175\n"
     ]
    }
   ],
   "source": [
    "best_id = np.argmax(cv_data['test-Accuracy-mean'])\n",
    "\n",
    "print(f\"Best mean accuracy: {np.round(cv_data['test-Accuracy-mean'][best_id], 3)}\")\n",
    "print(f\"Accuracy std: {np.round(cv_data['test-Accuracy-std'][best_id], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97eb7fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.8041958  0.81118881 0.83802817 0.87323944 0.8028169 ]\n",
      "mean accuracy: 0.8258938244853737\n",
      "accuracy std: 0.02686423341453882\n"
     ]
    }
   ],
   "source": [
    "classifier = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    cat_features=cat_cols + ['cluster'],\n",
    "    text_features=['Name'],\n",
    "    loss_function = metrics.Logloss(),\n",
    "    random_seed=SEED,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "model = Pipeline([\n",
    "    ('initial', FunctionTransformer(prep_data, kw_args=dict(fill_vall=-999))),\n",
    "    ('col_spliter', \n",
    "     ColumnTransformer(\n",
    "         [('pass', 'passthrough', ['Name'] + cat_cols),\n",
    "          ('preps', \n",
    "           Pipeline([\n",
    "               ('encoder',MEstimateEncoder(cols=cat_cols)),\n",
    "               ('scaler', StandardScaler()),\n",
    "               ('cluster', ClusterAdder()),\n",
    "               ('drop', FunctionTransformer(lambda x: x.drop(columns=cat_cols)))\n",
    "           ]),\n",
    "           [col for col in prep_data(X_train).columns if col != 'Name']\n",
    "          )\n",
    "         ], \n",
    "         remainder='passthrough',\n",
    "         verbose_feature_names_out=False\n",
    "     )\n",
    "    ),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "scores = cross_val_score(\n",
    "    estimator=model,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    scoring='accuracy',\n",
    "    cv=CV,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "print(f'Scores: {scores}')\n",
    "print(f'mean accuracy: {scores.mean()}')\n",
    "print(f'accuracy std: {scores.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2f583",
   "metadata": {},
   "source": [
    "## Логистическая регрессия как признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProbAdder(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, frac=0.05, C=0.1, penalty='l1'):\n",
    "#         self.frac = frac\n",
    "#         self.C = C\n",
    "#         self.penalty = penalty\n",
    "        \n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "        \n",
    "#         selected_X = X.sample(frac=self.frac)\n",
    "#         selected_y = y[selected_X.index]\n",
    "        \n",
    "#         self.model = (\n",
    "#             LogisticRegression(\n",
    "#                 penalty=self.penalty, \n",
    "#                 C=self.C, \n",
    "#                 class_weight='balanced', \n",
    "#                 solver='liblinear'\n",
    "#             )\n",
    "#             .fit(selected_X, selected_y)\n",
    "#         )\n",
    "        \n",
    "#         return self\n",
    "    \n",
    "    \n",
    "#     def transform(self, X, y=None):\n",
    "#         res=X.copy()\n",
    "#         res['prob'] = self.model.predict_proba(X)[:, 1]\n",
    "        \n",
    "#         return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preps = Pipeline([\n",
    "#     ('initial', FunctionTransformer(prep_data, kw_args=dict(fill_vall=-999))),\n",
    "#     ('col_spliter', \n",
    "#      ColumnTransformer(\n",
    "#          [('pass', 'passthrough', ['Name'] + cat_cols),\n",
    "#           ('preps', \n",
    "#            Pipeline([\n",
    "#                ('encoder',MEstimateEncoder(cols=cat_cols)),\n",
    "#                ('scaler', StandardScaler()),\n",
    "#                ('cluster', ClusterAdder()),\n",
    "#                ('prob', ProbAdder()),\n",
    "#                ('drop', FunctionTransformer(lambda x: x.drop(columns=cat_cols)))\n",
    "#            ]),\n",
    "#            [col for col in prep_data(X_train).columns if col != 'Name']\n",
    "#           )\n",
    "#          ], \n",
    "#          remainder='passthrough',\n",
    "#          verbose_feature_names_out=False\n",
    "#      )\n",
    "#     ),\n",
    "# ])\n",
    "\n",
    "# prepared_data = data_preps.fit_transform(X_train, y_train)\n",
    "\n",
    "# train_pool = Pool(\n",
    "#     data=prepared_data, \n",
    "#     label=y_train, \n",
    "#     cat_features=cat_cols + ['cluster'],\n",
    "#     text_features=['Name']\n",
    "# )\n",
    "\n",
    "# model = CatBoostClassifier(\n",
    "#     loss_function = metrics.Logloss(),\n",
    "#     custom_loss=[metrics.Accuracy(), metrics.AUC()],\n",
    "#     random_seed=SEED,\n",
    "#     verbose=False,\n",
    "# )\n",
    "\n",
    "# cv_data = cv(\n",
    "#     pool=train_pool, \n",
    "#     params=model.get_params(), \n",
    "#     logging_level='Silent', \n",
    "#     stratified=True, \n",
    "#     plot=True,\n",
    "#     fold_count=CV,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_id = np.argmax(cv_data['test-Accuracy-mean'])\n",
    "\n",
    "# print(f\"Best mean accuracy: {np.round(cv_data['test-Accuracy-mean'][best_id], 3)}\")\n",
    "# print(f\"Accuracy std: {np.round(cv_data['test-Accuracy-std'][best_id], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = CatBoostClassifier(\n",
    "#     iterations=1000,\n",
    "#     cat_features=cat_cols + ['cluster'],\n",
    "#     text_features=['Name'],\n",
    "#     loss_function = metrics.Logloss(),\n",
    "#     random_seed=SEED,\n",
    "#     verbose=False,\n",
    "# )\n",
    "\n",
    "\n",
    "# final_pipeline = Pipeline([\n",
    "#     ('initial', FunctionTransformer(prep_data, kw_args=dict(fill_vall=-999))),\n",
    "#     ('col_spliter', \n",
    "#      ColumnTransformer(\n",
    "#          [('pass', 'passthrough', ['Name'] + cat_cols),\n",
    "#           ('preps', \n",
    "#            Pipeline([\n",
    "#                ('encoder',MEstimateEncoder(cols=cat_cols)),\n",
    "#                ('scaler', StandardScaler()),\n",
    "#                ('cluster', ClusterAdder()),\n",
    "#                ('prob', ProbAdder(frac=1)),\n",
    "#                ('drop', FunctionTransformer(lambda x: x.drop(columns=cat_cols)))\n",
    "#            ]),\n",
    "#            [col for col in prep_data(X_train).columns if col != 'Name']\n",
    "#           )\n",
    "#          ], \n",
    "#          remainder='passthrough',\n",
    "#          verbose_feature_names_out=False\n",
    "#      )\n",
    "#     ),\n",
    "#     ('classifier', classifier)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd1eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = cross_val_score(\n",
    "#     estimator=final_pipeline,\n",
    "#     X=X_train,\n",
    "#     y=y_train,\n",
    "#     scoring='accuracy',\n",
    "#     cv=CV,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "\n",
    "# print(f'Scores: {scores}')\n",
    "# print(f'mean accuracy: {scores.mean()}')\n",
    "# print(f'accuracy std: {scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2bfc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549a4f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(\n",
    "        pd\n",
    "        .DataFrame(\n",
    "            final_pipeline['classifier'].get_feature_importance(),\n",
    "            index=final_pipeline[:-1].transform(X_train).columns,\n",
    "            columns=['feature_importance']\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(by='feature_importance', ascending=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880ccb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5553534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
